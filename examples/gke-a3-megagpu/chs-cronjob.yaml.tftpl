# Copyright 2026 "Google LLC"
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: batch/v1
kind: CronJob
metadata:
  name: cluster-health-scanner-cronjob
spec:
  schedule: "${cronjob_schedule}"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  suspend: false
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: workload-identity-k8s-sa
          containers:
          - name: chs-runner
            image: python:3.11-slim-buster
            imagePullPolicy: Always
            command:
            - /bin/bash
            - -c
            - |
              set -ex
              set -x
              apt-get update && apt-get install -y git curl gnupg -y
              git clone https://github.com/GoogleCloudPlatform/cluster-health-scanner
              cd cluster-health-scanner
              apt-get install -y apt-transport-https ca-certificates
              curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
              echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
              apt-get update
              apt-get install -y google-cloud-cli kubectl
              apt-get install -y google-cloud-cli-gke-gcloud-auth-plugin
              curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
              pip3 install -r cli/requirements.txt
              gcloud container clusters get-credentials ${deployment_name} --region ${region} --project ${project_id}
              OUTPUT_DIR="/mnt/output"
              mkdir -p $OUTPUT_DIR
              TIMESTAMP="`date "+%Y-%m-%d %H:%M:%S"`"
              OUTPUT_FILENAME="${deployment_name}_healthscan_result_$TIMESTAMP.txt"
              FULL_OUTPUT_PATH="$OUTPUT_DIR/$OUTPUT_FILENAME"
              python3 cli/cluster_diag.py -o gke healthscan ${machine_type} -c gpu --run_only_on_available_nodes
              python3 cli/cluster_diag.py -o gke healthscan ${machine_type} -c nccl --run_only_on_available_nodes
              python3 cli/cluster_diag.py -o gke healthscan ${machine_type} -c straggler --run_only_on_available_nodes
              python3 cli/cluster_diag.py -o gke healthscan ${machine_type} -c neper --run_only_on_available_nodes
              python3 cli/cluster_diag.py -o gke healthscan ${machine_type} -c tinymax --run_only_on_available_nodes
              #python3 cli/cluster_diag.py -o gke healthscan ${machine_type} -c status --run_only_on_available_nodes > "$FULL_OUTPUT_PATH" 2>&1
              kubectl get nodes -o custom-columns="NODE:.metadata.name,NCCL_MARK:.metadata.labels.aiinfra/nccl-healthcheck-test,NCCL_BANDWIDTH:.metadata.labels.aiinfra/nccl-healthcheck-bandwidth,NCCL_RESULT:.metadata.labels.aiinfra/nccl-healthcheck-result,NCCL_RUNTIME:.metadata.labels.aiinfra/nccl-healthcheck-runtime-sec,TINYMAX_MARK:.metadata.labels.aiinfra/tinymax-healthcheck-test,TINYMAX_RESULT:.metadata.labels.aiinfra/tinymax-healthcheck-result,TINYMAX_RUNTIME:.metadata.labels.aiinfra/tinymax-healthcheck-runtime-sec,GPU_MARK:.metadata.labels.aiinfra/gpu-healthcheck-test,GPU_RESULT:.metadata.labels.aiinfra/gpu-healthcheck-result,GPU_RUNTIME:.metadata.labels.aiinfra/gpu-healthcheck-runtime-sec" > "$FULL_OUTPUT_PATH" 2>&1
              echo "Health scan outputs saved to $OUTPUT_DIR"
              echo "Final output file: $OUTPUT_FILENAME"
            volumeMounts: 
            - name: ${gcs_bucket}
              mountPath: /mnt/output
          volumes:
          - name: ${gcs_bucket}
            persistentVolumeClaim:
              claimName: ${gcs_pvc}
          restartPolicy: Never
          tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
          - key: "components.gke.io/gke-managed-components"
            operator: "Exists"
            effect: "NoSchedule"
      backoffLimit: 0
