# Copyright 2021 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---

blueprint_name: hpc-cluster-high-io

vars:
  project_id:  ## Set GCP Project ID Here ##
  deployment_name: hpc-high-io
  region: us-central1
  zone: us-central1-c

# The following commented block will use a GCS bucket to store and manage the
# terraform state. Add your own bucket name and (optionally) a service account
# in the configuration. If not set, the terraform state will be stored locally
# within the generated blueprint.
# terraform_backend_defaults:
#   type: gcs
#   configuration:
#     bucket: a_bucket
#     impersonate_service_account: a_bucket_reader@project.iam.gserviceaccount.com

resource_groups:
- group: primary
  resources:
  # Source is an embedded resource, denoted by "resources/*" without ./, ../, /
  # as a prefix. To refer to a local resource, prefix with ./, ../ or /
  # Example - ./resources/network/pre-existing-vpc
  - source: resources/network/pre-existing-vpc
    kind: terraform
    id: network1

  - source: resources/file-system/filestore
    kind: terraform
    id: homefs
    use: [network1]
    settings:
      local_mount: /home

  - source: resources/file-system/filestore
    kind: terraform
    id: projectsfs
    use: [network1]
    settings:
      filestore_tier: HIGH_SCALE_SSD
      size_gb: 10240
      local_mount: /projects

  - source: resources/third-party/file-system/DDN-EXAScaler
    kind: terraform
    id: scratchfs
    use: [network1]
    settings:
      local_mount: /scratch

  - source: resources/third-party/compute/SchedMD-slurm-on-gcp-partition
    kind: terraform
    id: low_cost_partition
    use:
    - network1
    - homefs
    - scratchfs
    - projectsfs
    settings:
      partition_name: low_cost
      max_node_count: 10
      enable_placement: false
      machine_type: n2-standard-4

  # This compute_partition is far more performant than low_cost_partition.
  - source: resources/third-party/compute/SchedMD-slurm-on-gcp-partition
    kind: terraform
    id: compute_partition
    use:
    - network1
    - homefs
    - scratchfs
    - projectsfs
    settings:
      max_node_count: 200
      partition_name: compute

  - source: resources/third-party/scheduler/SchedMD-slurm-on-gcp-controller
    kind: terraform
    id: slurm_controller
    use:
    - network1
    - homefs
    - scratchfs
    - projectsfs
    - low_cost_partition  # low cost partition will be default as it is listed first
    - compute_partition

  - source: resources/third-party/scheduler/SchedMD-slurm-on-gcp-login-node
    kind: terraform
    id: slurm_login
    use:
    - network1
    - homefs
    - scratchfs
    - projectsfs
    - slurm_controller
    settings:
      login_machine_type: n2-standard-4
