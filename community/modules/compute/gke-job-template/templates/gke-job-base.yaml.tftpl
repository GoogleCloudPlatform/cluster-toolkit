---
apiVersion: batch/v1
kind: Job
metadata:
  name: ${name}${suffix}
  labels:
  %{~ for key, val in labels ~}
    ${key}: ${val}
  %{~ endfor ~}
spec:
  parallelism: ${node_count}
  completions: ${node_count}
  template:
    spec:
      %{~ if length(node_pool_names) > 0 ~}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: cloud.google.com/gke-nodepool
                operator: In
                values:
                %{~ for node_pool in node_pool_names ~}
                - ${node_pool}
                %{~ endfor ~}
      %{~ endif ~}
      %{~ if length(node_selectors) > 0 ~}
      nodeSelector:
      %{~ for selector in node_selectors ~}
        ${selector.key}: ${selector.value}
      %{~ endfor ~}
      %{~ endif ~}
      tolerations:
      %{~ for toleration in tolerations ~}
      - key: ${toleration.key}
        operator: ${toleration.operator}
        value: "${toleration.value}"
        effect: ${toleration.effect}
      %{~ endfor ~}
      containers:
      - name: ${name}-container
        image: ${image}
        command: [%{~ for s in command ~}"${s}",%{~ endfor ~}]
        %{~ if gpu_limit != null || cpu_request != null ~}
        resources:
          %{~ if gpu_limit != null ~}
          limits:
            # GPUs should only be specified as limits
            # https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/
            nvidia.com/gpu: ${gpu_limit}
          %{~ endif ~}
          %{~ if cpu_request != null ~}
          requests:
            %{~ if full_node_request ~}
            # cpu request attempts full node per pod
            %{~ endif ~}
            cpu: ${cpu_request}
          %{~ endif ~}
        %{~ endif ~}
      restartPolicy: ${restart_policy}
  backoffLimit: ${backoff_limit}
