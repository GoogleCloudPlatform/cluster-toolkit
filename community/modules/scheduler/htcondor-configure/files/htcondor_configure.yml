# Copyright 2022 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---
- name: Configure HTCondor Role
  hosts: localhost
  become: true
  vars:
    job_queue_ha: false
    spool_dir: /var/lib/condor/spool
    condor_config_root: /etc/condor
    role_file: 00-role
    pool_file: 01-pool
    cm_config_file: 02-central-manager
    cm_ha_config_file: 02-central-manager-high-availability
    schedd_config_file: 02-schedd
    schedd_ha_config_file: 02-schedd-high-availability
    execute_config_file: 02-execute
  tasks:
  - name: User must supply HTCondor role
    ansible.builtin.assert:
      that:
      - htcondor_central_manager_ips is defined
      - htcondor_role is defined
      - password_id is defined
      - project_id is defined
  - name: Set Trust Domain
    ansible.builtin.set_fact:
      trust_domain: c.{{ project_id }}.internal
  - name: Set HTCondor Pool password (token signing key)
    ansible.builtin.shell: |
      set -e -o pipefail
      export CLOUDSDK_PYTHON=/usr/bin/python
      POOL_PASSWORD=$(gcloud secrets versions access latest --secret={{ password_id }})
      echo -n "$POOL_PASSWORD" | sh -c "condor_store_cred add -c -i -"
    args:
      creates: "{{ condor_config_root }}/passwords.d/POOL"
  - name: Remove default HTCondor configuration
    ansible.builtin.file:
      path: "{{ condor_config_root }}/config.d/00-htcondor-9.0.config"
      state: absent
    notify:
    - Reload HTCondor
  - name: Set HTCondor role on all hosts
    ansible.builtin.copy:
      dest: "{{ condor_config_root }}/config.d/{{ role_file }}"
      mode: 0644
      content: |
        use role:{{ htcondor_role }}
    notify:
    - Reload HTCondor
  - name: Set HTCondor Central Manager and trust domain on all hosts
    ansible.builtin.copy:
      dest: "{{ condor_config_root }}/config.d/{{ pool_file }}"
      mode: 0644
      content: |
        CONDOR_HOST={{ htcondor_central_manager_ips }}
        UID_DOMAIN={{ trust_domain }}
        TRUST_DOMAIN={{ trust_domain }}
    notify:
    - Reload HTCondor
  - name: Configure HTCondor Central Manager
    when: htcondor_role == 'get_htcondor_central_manager'
    block:
    - name: Create IDTOKEN for Central Manager
      ansible.builtin.shell: |
        umask 0077
        TRUST_DOMAIN=$(condor_config_val TRUST_DOMAIN)
        # do not restrict Central Manager authz scopes!
        condor_token_create -identity condor@{{ trust_domain }} \
          -token condor@{{ trust_domain }}
      args:
        creates: "{{ condor_config_root }}/tokens.d/condor@{{ trust_domain }}"
    - name: Generate list of Central Managers
      ansible.builtin.set_fact:
        central_manager_list: "{{ htcondor_central_manager_ips | split(',') }}"
    - name: Create Central Manager standard configuration file
      ansible.builtin.copy:
        dest: "{{ condor_config_root }}/config.d/{{ cm_config_file }}"
        mode: 0644
        content: |
          COLLECTOR_UPDATE_INTERVAL=30
          NEGOTIATOR_UPDATE_INTERVAL=30
          NEGOTIATOR_DEPTH_FIRST=True
          NEGOTIATOR_UPDATE_AFTER_CYCLE=True
      notify:
      - Reload HTCondor
    - name: Create Central Manager HA configuration file
      when: central_manager_list | length > 1
      ansible.builtin.copy:
        dest: "{{ condor_config_root }}/config.d/{{ cm_ha_config_file }}"
        mode: 0644
        content: |
          # following https://htcondor.readthedocs.io/en/latest/admin-manual/high-availability.html#high-availability-of-the-central-manager
          CM_LIST = \
            {{ central_manager_list[0] }}:$(SHARED_PORT_PORT), \
            {{ central_manager_list[1] }}:$(SHARED_PORT_PORT)

          HAD_USE_SHARED_PORT=True
          HAD_LIST=$(CM_LIST)

          REPLICATION_USE_SHARED_PORT=True
          REPLICATION_LIST=$(CM_LIST)

          HAD_USE_PRIMARY=True
          HAD_CONTROLLEE=NEGOTIATOR
          MASTER_NEGOTIATOR_CONTROLLER=HAD

          DAEMON_LIST=$(DAEMON_LIST), HAD, REPLICATION
          HAD_USE_REPLICATION=True
          MASTER_HAD_BACKOFF_CONSTANT=360
      notify:
      - Restart HTCondor
    - name: Remove Central Manager HA configuration file
      when: central_manager_list | length == 1
      ansible.builtin.file:
        path: "{{ condor_config_root }}/config.d/{{ cm_ha_config_file }}"
        state: absent
      notify:
      - Restart HTCondor
  - name: Configure HTCondor SchedD
    when: htcondor_role == 'get_htcondor_submit'
    block:
    - name: Setup Spool directory
      ansible.builtin.file:
        path: "{{ spool_dir }}"
        state: directory
        owner: condor
        group: condor
        mode: 0755
    - name: Create SchedD configuration file
      ansible.builtin.copy:
        dest: "{{ condor_config_root }}/config.d/{{ schedd_config_file }}"
        mode: 0644
        content: |
          SCHEDD_INTERVAL=30
          TRUST_UID_DOMAIN=True
          SUBMIT_ATTRS=RunAsOwner
          RunAsOwner=True
          use feature:JobsHaveInstanceIDs
          SYSTEM_JOB_MACHINE_ATTRS=$(SYSTEM_JOB_MACHINE_ATTRS) \
            CloudVMType CloudZone CloudInterruptible
          SYSTEM_JOB_MACHINE_ATTRS_HISTORY_LENGTH=10
          SPOOL={{ spool_dir }}
          use feature:ScheddCronOneShot(cloud, $(LIBEXEC)/common-cloud-attributes-google.py)
          SCHEDD_CRON_cloud_PREFIX=Cloud
          # the sequence of job transforms and submit requirements below set
          # a default job attribute RequireSpot to False but allow the user to
          # specify *only* a boolean value with +RequireSpot = True in their job
          # submit file; the requirements of the job are transformed to filter
          # on +RequireSpot unless job has explicit CloudInterruptible requirements
          JOB_TRANSFORM_NAMES = SPOT_DEFAULT, SPOT_REQS
          JOB_TRANSFORM_SPOT_DEFAULT @=end
             DEFAULT RequireSpot False
          @end
          # Unless explicit, set CloudInterruptible requirements to job RequireSpot attribute
          JOB_TRANSFORM_SPOT_REQS @=end
             REQUIREMENTS ! unresolved(Requirements, "^CloudInterruptible$")
             SET Requirements $(MY.Requirements) && (CloudInterruptible is My.RequireSpot)
          @end
          SUBMIT_REQUIREMENT_NAMES = REQSPOT
          SUBMIT_REQUIREMENT_REQSPOT = isBoolean(RequireSpot)
          SUBMIT_REQUIREMENT_REQSPOT_REASON = "Jobs must set +RequireSpot to either True or False"
      notify:
      - Reload HTCondor
    - name: Create IDTOKEN to advertise access point
      ansible.builtin.shell: |
        umask 0077
        # DAEMON authorization can likely be removed in future when scopes
        # needed to trigger a negotiation cycle are changed. Suggest review
        # https://opensciencegrid.atlassian.net/jira/software/c/projects/HTCONDOR/issues/?filter=allissues
        condor_token_create -authz READ -authz ADVERTISE_MASTER \
          -authz ADVERTISE_SCHEDD -authz DAEMON -identity condor@{{ trust_domain }} \
          -token condor@{{ trust_domain }}
      args:
        creates: "{{ condor_config_root }}/tokens.d/condor@{{ trust_domain }}"
    - name: Enable SchedD high availability
      when: job_queue_ha | bool
      block:
      - name: Set SchedD HA configuration (requires restart)
        ansible.builtin.copy:
          dest: "{{ condor_config_root }}/config.d/{{ schedd_ha_config_file }}"
          mode: 0644
          content: |
            MASTER_HA_LIST=SCHEDD
            HA_LOCK_URL=file:{{ spool_dir }}
            VALID_SPOOL_FILES=$(VALID_SPOOL_FILES), SCHEDD.lock
            HA_POLL_PERIOD=30
            SCHEDD_NAME=had-schedd@
        notify:
        - Restart HTCondor
      # although HTCondor is guaranteed to start after mounting remote
      # filesystems is *attempted*, it does not guarantee successful mounts;
      # this additional SystemD setting will refuse to start HTCondor if the
      # spool shared filesystem has not been mounted
      - name: Create SystemD override directory for HTCondor
        ansible.builtin.file:
          path: /etc/systemd/system/condor.service.d
          state: directory
          owner: root
          group: root
          mode: 0755
      - name: Ensure HTCondor starts after shared filesystem is mounted
        ansible.builtin.copy:
          dest: /etc/systemd/system/condor.service.d/mount-spool.conf
          mode: 0644
          content: |
            [Unit]
            RequiresMountsFor={{ spool_dir }}
        notify:
        - Reload HTCondor SystemD unit
    - name: Disable SchedD high availability
      when: not job_queue_ha | bool
      block:
      - name: Remove SchedD HA configuration file
        ansible.builtin.file:
          path: "{{ condor_config_root }}/config.d/{{ schedd_ha_config_file }}"
          state: absent
        notify:
        - Restart HTCondor
      - name: Remove HTCondor SystemD override
        ansible.builtin.file:
          path: /etc/systemd/system/condor.service.d/mount-spool.conf
          state: absent
        notify:
        - Reload HTCondor SystemD unit
  - name: Configure HTCondor StartD
    when: htcondor_role == 'get_htcondor_execute'
    block:
    - name: Create StartD configuration file
      ansible.builtin.copy:
        dest: "{{ condor_config_root }}/config.d/{{ execute_config_file }}"
        mode: 0644
        content: |
          use feature:PartitionableSlot
          use feature:CommonCloudAttributesGoogle("-c created-by")
          UPDATE_INTERVAL=30
          TRUST_UID_DOMAIN=True
          STARTER_ALLOW_RUNAS_OWNER=True
          RUNBENCHMARKS=False
      notify:
      - Reload HTCondor
    - name: Create IDTOKEN to advertise execute point
      ansible.builtin.shell: |
        umask 0077
        condor_token_create -authz READ -authz ADVERTISE_MASTER \
          -authz ADVERTISE_STARTD -identity condor@{{ trust_domain }} \
          -token condor@{{ trust_domain }}
      args:
        creates: "{{ condor_config_root }}/tokens.d/condor@{{ trust_domain }}"
  handlers:
  - name: Reload HTCondor SystemD unit
    ansible.builtin.systemd:
      daemon_reload: true
  - name: Restart HTCondor
    ansible.builtin.service:
      name: condor
      state: restarted
  - name: Reload HTCondor
    ansible.builtin.service:
      name: condor
      state: reloaded
  post_tasks:
  - name: Start HTCondor
    ansible.builtin.service:
      name: condor
      state: started
      enabled: true
  - name: Inform users
    changed_when: false
    ansible.builtin.shell: |
      set -e -o pipefail
      wall "******* HTCondor system configuration complete ********"
