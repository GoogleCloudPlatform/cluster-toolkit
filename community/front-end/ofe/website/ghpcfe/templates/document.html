<!--
 Copyright 2026 Google LLC

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

{% extends "base_generic.html" %}

{% block content %}

<h2>Documentation</h2>

<a name="users"><h4>Users</h4></a>

<p>This website can only be accessed by authenticated users. There are three
types of users:</p>
<ul>
<li>Viewers - these are users with read-only access to the system.
They are able to view clusters, applications and jobs.</li>
<li>Normal Users - in addition to what Viewers can do, they are able to
prepare and submit jobs to run on clusters.</li>
<li>Cluster Admins - these are the users with administration privileges. In
addition to what Normal Users can do, they can set up credentials, create and 
manage clusters, and set up/install applications on clusters. Cluster Admins
are normally the owners of cloud resources, e.g. owners of GCP projects, 
or somebody who are delegated with sufficient permission.</li>
</ul>

<p>The preferred way to access this system is through Google identities. 
Admin users may also create user accounts.</p>

<hr>
<a name="credentials"><h4>Credentials</h4></a>

<p>This section is for Cluster Admin users. Normal user should skip this 
section as the admin users should have prepared the credentials already.</p>

<p>This system helps you to automate many activities on your chosen cloud 
platform. For this to work, register your cloud credentials with this system.
Credentials will be validated against the cloud platforms and saved for future 
uses. </p>

<p>Cloud credentials come in different forms depending on which cloud 
provider you are using. Typically they can be found from the web interface
of your cloud provider or obtained from command line.

<a name="credentials-gcp"><h5>GCP</h5></a>
<p>The preferred way accessing GCP resources from this system is through a 
<a href="https://cloud.google.com/iam/docs/service-accounts" target="_blank">Service Account</a>. 
To create a service account: your account must have sufficient permissions. 
If you are not the <strong>Owner</strong> or <strong>Editor</strong> of the 
GCP project, follow the instructions below. When certain permissions are
missing, GCP will give clear error messages. Note the permissions required,
locate them in <a href="https://cloud.google.com/iam/docs/understanding-roles" target="_blank">this page</a>, and identify suitable
roles that provide them. Ask the project Owner to assign those extra roles
to your user account. Some relevant roles include Service Account User,
Service Account Admin, and Service Account Key Admin.</p>

<p><strong>From	GCP console</strong></p>

<ol>
<li>Log in to your GCP console and select the GCP project to host this
work.</li>
<li>From the main menu, select IAM & Admin, then Service Accounts.</li>
<li>Click the CREATE SERVICE ACCOUNT button.</li>
<li>Name your service account, optionally provide a description, and then
click the CREATE button.</li>
<li>Grant your service account the following roles: Editor, Security Admin.</li>
<li>You may give some human users access to this service account but that is 
not required by this system. Clock Done button.</li>
<li>Locate the new service account from the list, click Manage Keys from 
Actions menu.</li>
<li>Click ADD KEY, then Create new key. Select JSON as key type, and click the
CREATE button.</li>
<li>Save the generated JSON content which should be pasted in the credential
creation form here on this website.</li>
</ol> 

<p><strong>From command line</strong></p>

<p>It is assumed that you have the gcloud command-line tool installed on your
development system, or use GCP cloud shell which has this tool pre-installed. </p>


<hr>

<a name="clusters"><h4>Clusters</h4></a>

<p>In the simplest setting, an organisation may create one HPC cluster per cloud
platform. This is because one cluster can support multiple machine types. There 
are, of course, many good reasons to create multiple clusters on the same 
platform, e.g. for project management purpose, or to map cloud usages to
organisational structures.</p>
<p>For each cluster, admin users can choose the suitable machine types for the
organisation's workloads and impose resource limits, e.g. the maximum number 
of compute nodes for each machine types.</p>
<p>At any time, each cluster is in one of the following status:</p>
<ul>
<li><strong>New</strong>: Cluster is being newly configured by a user through the web interface.</li>
<li><strong>Creating</strong>: Cluster is being created (i.e. hardware is being brought up online).</li>
<li><strong>Initialising</strong>: Cluster is being initialised (i.e. software is being installed and environment is being prepared). By default, these clusters use a CentOS 7 based operating system with software preconfigured to support distributed MPI and hybrid jobs.</li>
<li><strong>Ready</strong>: Cluster is ready for jobs.</li>
<li><strong>Terminating</strong>: Cluster is being terminated.</li>
<li><strong>Stopped</strong>: Cluster is stopped (can be restarted).</li>
<li><strong>Deleted</strong>: Cluster has been deleted (cannot be restarted). Historical information of this cluster will be retained in the database.</li>
</ul> 
<p>Depending on the current cluster status, actions are made available on the
website to perform management tasks, e.g. cluster can be created when it is in 
'New' status or paused (stopped) when it is in 'Ready' status. Most management
tasks are performed asynchronously in the background. For example, cluster 
creation may take more than 20 minutes to complete. Visual indication is
available on the website when background tasks are ongoing.</p>
<p>When a cluster is ready, applications can be installed by Cluster Admin
users.</p>

<hr>
<a name="applications"><h4>Applications</h4></a>
<p>Applications can be installed on HPC clusters using either Spack or custom 
means. Spack, an established package management system for HPC, contains
build recipes of most widely used applications, including almost all popular 
open-source packages. For applications not yet covered by the Spack 
package repository, e.g. codes developed in-house, or commercial packages 
that require complex set-up, a script-based approach can be used register them
to the system.</p>
<p>Note that an application in this system refers to a unique binary
installation of a package, as identified by a software version, and a specific
target architecture. Spack has intrinsic support on both of these factors,
generating multiple binaries as required. Spack also builds variants of the same software, e.g. packages with optional features switched on. Experienced users should be able to specify such using Spack specifiers.</p>

<a name="spack-applications"><h5>Spack applications</h5></a>
<p>Each application is in one of the following status:</p>
<ul>
<li><strong>New</strong>: Application is being newly configured by a user through the web interface. At this stage, only a database record gets created in the system.</li>
<li><strong>Preparing</strong>: Application build is triggered from the website and information is being passed on to the cluster.</li>  
<li><strong>Queueing</strong>: The job to build this application in queueing on the target cluster.</li>
<li><strong>Installing</strong>: The job to build this application in running on the target cluster. Spack is fully responsible for building this application and managing its dependencies.</li>
<li><strong>Ready</strong>: Spack build has completed successfully and the application is ready to run on the current cluster. </li>
<li><strong>Failed</strong>: Spack has somehow failed to build this application. See <a href="#troubleshooting">Troubleshooting</a> section below for debugging information.</li>
</ul>
<p>A typical work flow for installing a new Spack application is as follows:</p>
<ul>
  <li>From the cluster list page, identify the target cluster, and click <em>Install Spack Application</em> from its <em>Actions menu</em>. Alternatively, click the <em>Install Spack Application</em> button from the cluster detail page.
</li>
  <li>In the <em>Create a new application</em> form, in the <em>Spack name</em> field, type a keyword and use the auto-completion function to choose the Spack package you want to install. The <em>Name</em> and <em>Version</em> fields get populated automatically. If Spack supports multiple versions of the same application, click the dropdown list to select the desired version.</li>
  <li>Spack supports variants - applications built with customised compile-time options. These may be special compiler flags, or optional feature that must be switched on manually. Advanced users may supply additional specs using the optional <em>Spack spec</em> field.</li>
  <li>The <em>Description</em> field is populated automatically from the information found in the Spack repository.</li>
  <li>Choose a <em>Install instance</em> from the dropdown list. Some applications can benefit from parallel build. If this is known to be the case, an instance with higher number of vCPUs may speed up the installation process.</li>
  <li>Select one or more <em>Instance type</em> from the list. This field specifies the target machines on which this application installation is valid and able to run. Spack generates the most suitable binaries depending on this information. For example, if the c2 family is chosen on GCP, Spack understands that the CPU architecture is Intel "cascadelake" and generates the optimised binary for it accordingly. If both c2 and n2d (AMD Rome architecture) are selected (Ctrl click for multiple selection), Spack will generate common "x86-64" binaries that can run on both Intel and AMD processors. Cluster Admins decides which machine types are available for each cluster. Users are responsible to choose the most suitable machine types for application builds, striking a balance between performance and compatibility. </li> 
  <li>Click <em>Save</em> button. At this stage, only a database record has been created in the system. On the next page, click the <em>Edit</em> button to modify the application settings; click the <em>Delete</em> button to delete this record. Click the <em>Spack install</em> button to actually start building this application on the cluster. This last step can take quite a while to complete depending on applications. A visual indication is given on the application detail page until the installation job gets completed.</li>
  <li>Successfully installed application will have its status updated stating so. A <em>New Job</em> button becomes available from the <em>Actions</em> menu on the application list page, or from the application detail page.</li>
</ul>  


<a name="other-applications"><h5>Other applications</h5></a>

<hr>
<a name="jobs"><h4>Jobs</h4></a>

<hr>
<a name="troubleshooting"><h4>Troubleshooting</h4></a>

<a name="ssh-access"><h5>SSH access</h5></a>

<p>SSH access to cluster head nodes may be necessary for debugging purposes.</p>
<p>Currently, Cluster Admin users may SSH into clusters via the service machine (machine hosting this website) using a special user account called 'citc'. This account is automatically set up when a new cluster is being created.</p> 
<p>Cluster Admins have the option to add authorized users when creating new clusters. If these ordinary users have their public SSH keys registered with the system, they can also gain access to the clusters.

<a name="log-files"><h5>Log files</h5></a>
<ul>
  <li><em>/root/ansible-pull.log</em> - log for cluster set-up</li>
  <li><em>/mnt/shared/benchmarks/install_&lt;application_id&gt;_&lt;machine_type&gt;</em> - logs for Spack application installations</li>
</ul>

{% endblock %}
